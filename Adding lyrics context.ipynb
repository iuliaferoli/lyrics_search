{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the Elasticsearch client with your credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the HF + ELSER example to the Spotify data example by adding a lyrics dataset in there too.\n",
    "https://huggingface.co/datasets/brunokreiner/genius-lyrics\n",
    "* Connecting to data from HF - show the way to add a elastic engine to it - first quick and dirty example\n",
    "\n",
    "* Use the Spotify ID to add it to the Spotify index \n",
    "* Adding the ELSER model and a sentiment analysis model\n",
    "* Make a hybrid search example (search for artist + mood from sentiment for example) \n",
    "    * Maybe sort Taylor songs by mood?\n",
    "    * Follow up with GenAI example to sort songs into the stages of grief thing? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from getpass import getpass\n",
    "\n",
    "#Connect to the elastic cloud server\n",
    "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
    "ELASTIC_API_KEY = getpass(\"Elastic API Key: \")\n",
    "\n",
    "# Create an Elasticsearch client using the provided credentials\n",
    "client = Elasticsearch(\n",
    "    cloud_id=ELASTIC_CLOUD_ID,  # cloud id can be found under deployment management\n",
    "    api_key=ELASTIC_API_KEY, # your username and password for connecting to elastic, found under Deplouments - Security\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD HUGGING FACE DATASET CONNECTION \n",
    "\n",
    "https://huggingface.co/datasets/brunokreiner/genius-lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the data in an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating a nested field for the lyrics so we can search for the inner hits to get the exact lines we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'ts_songs'\n",
    "\n",
    "mappings = {\n",
    "  \"properties\": {\n",
    "    \"lyrics\": {\n",
    "        \"type\": \"nested\",\n",
    "        \"properties\": {\n",
    "          \"line\": {\n",
    "            \"type\": \"text\"\n",
    "          }\n",
    "        }\n",
    "    },\n",
    "  }\n",
    "}\n",
    "\n",
    "# Create the Elasticsearch index with the specified name (delete if already existing)\n",
    "if client.indices.exists(index=index_name):\n",
    "    client.indices.delete(index=index_name)\n",
    "client.indices.create(index=index_name, mappings=mappings)\n",
    "\n",
    "def generate_docs(data, index_name):\n",
    "    for document in data:\n",
    "        yield dict(_index=index_name, _id=f\"{document['id']}\", _source=document)\n",
    "\n",
    "\n",
    "# Use the Elasticsearch helpers.bulk() method to index the DataFrame data into Elasticsearch\n",
    "load = helpers.bulk(client, generate_docs(songs, index_name), index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for a specific line in a song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use a nested query to look up words in our songs and get the specific passage where this would be mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 19 songs that fit, here are the top results:\n",
      "From Taylor Swift : You Are in Love: \n",
      "You are in love, true love\n",
      "\n",
      "From Taylor Swift : Dancing With Our Hands Tied: \n",
      "Oh, keeping you with me, I-\n",
      "\n",
      "From Taylor Swift : Come Back... Be Here: \n",
      "4 AM, the second day\n",
      "\n",
      "From Taylor Swift : New Romantics: \n",
      "Come on, come along with me\n",
      "\n",
      "From Taylor Swift : So It Goes...: \n",
      "Do bad things with you\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def simple_search(query):\n",
    "  query = {\n",
    "      \"nested\": {\n",
    "        \"path\": \"lyrics\",\n",
    "        \"query\": {\n",
    "          \"match\": {\n",
    "            \"lyrics.line\": query\n",
    "          }\n",
    "        },\n",
    "        \"inner_hits\" : {\n",
    "          \"docvalue_fields\" : [\n",
    "            \"lyrics.line.keyword\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "  }\n",
    "\n",
    "  #Run a simple query, for example looking for problems with the engine\n",
    "  response = client.search(index=index_name, query=query)\n",
    "\n",
    "  print(f'We get back {response[\"hits\"][\"total\"][\"value\"]} songs that fit, here are the top results:')\n",
    "  for hit in response[\"hits\"][\"hits\"][0:5]:\n",
    "      print(f'From {hit[\"_source\"][\"artist\"]} : {hit[\"_source\"][\"name\"]}: ')\n",
    "      for inner_hit in hit[\"inner_hits\"][\"lyrics\"][\"hits\"][\"hits\"][0:1]:\n",
    "          print(inner_hit[\"_source\"][\"line\"])\n",
    "      print()\n",
    "\n",
    "simple_search(\"I am in love with you\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is only returning exact matches, missing out on similar songs about \"lovers\", \"loving\", or any similar phrases which I might still want to find. \n",
    "\n",
    "So we can take this a step further and add a semantic search model into the mix, to help us really look for meaning in the lyrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding ELSER inference for semantic search\n",
    "\n",
    "We will use a [foreach](https://www.elastic.co/guide/en/elasticsearch/reference/current/foreach-processor.html) processor to loop through all lines of the lyrics.\n",
    "\n",
    "See [the ELSER Notebook](https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/search/03-ELSER.ipynb) for a simple get-started quide for semantic search; and [this document chunking example](https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/document-chunking/with-index-pipelines.ipynb) for another instance of embedding inner hits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'task': 'eclQBhHoS0CN09g-_bZM5w:63679788'})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.ingest.put_pipeline(\n",
    "    id=\"adding_ELSER_to_lyrics\", \n",
    "    processors=\n",
    "    [\n",
    "        {\n",
    "            \"foreach\": {\n",
    "                \"field\": \"lyrics\",\n",
    "                \"processor\": {\n",
    "                    \"inference\": {\n",
    "                        \"model_id\": \".elser_model_2\",\n",
    "                        \"input_output\": [\n",
    "                            {\"input_field\": \"_ingest._value.line\", \"output_field\": \"_ingest._value.tokens\"}\n",
    "                        ],\n",
    "                        \"on_failure\" : [\n",
    "                        {\n",
    "                            \"set\" : {\n",
    "                                \"field\": \"_ingest._value.errors\",\n",
    "                                \"value\": \"failed in foreach processor\"\n",
    "                            }\n",
    "                        }]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "mappings = {\n",
    "    \"dynamic\" : True,\n",
    "    \"properties\" : \n",
    "    {\n",
    "        \"lyrics\": {\n",
    "            \"type\": \"nested\",\n",
    "            \"properties\": {\n",
    "                \"line\" : {\n",
    "                    \"type\": \"text\",\n",
    "                    \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n",
    "                },\n",
    "                \"tokens\": { \n",
    "                    \"type\": \"sparse_vector\" \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#Creating the new index with enriched data\n",
    "index_name_new = \"ts_songs_semantic\"\n",
    "if client.indices.exists(index=index_name_new):\n",
    "    client.indices.delete(index=index_name_new)\n",
    "client.indices.create(index=index_name_new, mappings=mappings)\n",
    "\n",
    "client.reindex(body={\n",
    "      \"source\": {\n",
    "          \"index\": index_name},\n",
    "      \"dest\": {\"index\": index_name_new, \"pipeline\" : \"adding_ELSER_to_lyrics\"}\n",
    "    }, wait_for_completion=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the same query again, but using `text_expansion` on the generated tokens rather than `match` directly on the text field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 19 songs that fit, here are the top results:\n",
      "From Taylor Swift : You Are in Love: \n",
      "You are in love\n",
      "\n",
      "From Taylor Swift : Gorgeous: \n",
      "(I hate you so much)\n",
      "\n",
      "From Taylor Swift : End Game (Ft. Ed Sheeran & Future): \n",
      "You love it, I love it, too 'cause you my type (you my type)\n",
      "\n",
      "From Taylor Swift : Come Back... Be Here: \n",
      "This is falling in love in the cruelest way\n",
      "\n",
      "From Taylor Swift : Don't Blame Me: \n",
      "You're lovin' me\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def semantic_search(query):\n",
    "    query = {\n",
    "        \"nested\": {\n",
    "            \"path\": \"lyrics\",\n",
    "            \"query\": {\n",
    "                \"text_expansion\": {\n",
    "                    \"lyrics.tokens\": {\n",
    "                        \"model_id\": \".elser_model_2\",\n",
    "                        \"model_text\": query,\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"inner_hits\" : {\n",
    "                \"docvalue_fields\" : [\n",
    "                    \"lyrics.line.keyword\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    #Run a simple query, for example looking for problems with the engine\n",
    "    response = client.search(index=index_name_new, query=query)\n",
    "\n",
    "    print(f'We get back {response[\"hits\"][\"total\"][\"value\"]} songs that fit, here are the top results:')\n",
    "    for hit in response[\"hits\"][\"hits\"][0:5]:\n",
    "        print(f'From {hit[\"_source\"][\"artist\"]} : {hit[\"_source\"][\"name\"]}: ')\n",
    "        for inner_hit in hit[\"inner_hits\"][\"lyrics\"][\"hits\"][\"hits\"][0:1]:\n",
    "            print(inner_hit[\"_source\"][\"line\"])\n",
    "        print()\n",
    "\n",
    "semantic_search(\"I am in love with you\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the new semantic search layer, we actually get back pretty much every song in our sample dataset. \n",
    "\n",
    "This could either mean the model has too low of a treshold for the match, or that simply all songs are in some form about love. \n",
    "\n",
    "Let's try some more specific searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic search does seem to capture the meaning better, however it still seems like the spirit of the songs isn't fully represented. This may be due to the chunking strategy. In these examples, each line of the lyrics is its own document, however the sentences or paragraphs end up broken up and some of the context is lost. \n",
    "\n",
    "This brings up a very important point about semantic search - performance isn't only determined by the model chosen, but also the way data is processed and introduced to the model.\n",
    "Let's try a few strategies to offer the model more context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD SECTION TO MATCH THE SPOTIFY IDs TO THE EXISTING INDEX "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN hybrid search examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
