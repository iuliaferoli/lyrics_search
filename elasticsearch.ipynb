{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the Elasticsearch client with your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/sm4kh0y91fs5_fft4375wwh00000gn/T/ipykernel_64636/1843019271.py:2: DeprecationWarning: Importing from the 'elasticsearch.client' module is deprecated. Instead use 'elasticsearch' module for importing the client.\n",
      "  from elasticsearch.client import MlClient\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from getpass import getpass\n",
    "\n",
    "#Connect to the elastic cloud server\n",
    "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
    "ELASTIC_API_KEY = getpass(\"Elastic API Key: \")\n",
    "\n",
    "# Create an Elasticsearch client using the provided credentials\n",
    "client = Elasticsearch(\n",
    "    cloud_id=ELASTIC_CLOUD_ID,  # cloud id can be found under deployment management\n",
    "    api_key=ELASTIC_API_KEY, # your username and password for connecting to elastic, found under Deplouments - Security\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the samle lyrics data [we just downloaded with the API.](/lyrics.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/hozier_songs.json', 'r') as f:\n",
    "  songs = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, this is the format of each of our lyrics documents right now after the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 84741219,\n",
       " 'name': 'Cherry Wine ',\n",
       " 'artist': 'Hozier',\n",
       " 'lyrics': [{'line': 'Her eyes and words are so icy'},\n",
       "  {'line': 'Oh but she burns'},\n",
       "  {'line': 'Like rum on the fire'},\n",
       "  {'line': 'Hot and fast and angry as she can be'},\n",
       "  {'line': 'I walk my days on a wire.'},\n",
       "  {'line': \"It looks ugly, but it's clean,\"},\n",
       "  {'line': \"Oh momma, don't fuss over me.\"},\n",
       "  {'line': \"The way she tells me I'm hers and she is mine\"},\n",
       "  {'line': 'Open hand or closed fist would be fine'},\n",
       "  {'line': 'The blood is rare and sweet as cherry wine.'},\n",
       "  {'line': 'Calls of guilty thrown at me'},\n",
       "  {'line': '******* Th'}]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the data in an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating a nested field for the lyrics so we can search for the inner hits to get the exact lines we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'songs'\n",
    "\n",
    "mappings = {\n",
    "  \"properties\": {\n",
    "    \"lyrics\": {\n",
    "        \"type\": \"nested\",\n",
    "        \"properties\": {\n",
    "          \"line\": {\n",
    "            \"type\": \"text\"\n",
    "          }\n",
    "        }\n",
    "    },\n",
    "  }\n",
    "}\n",
    "\n",
    "# Create the Elasticsearch index with the specified name (delete if already existing)\n",
    "if client.indices.exists(index=index_name):\n",
    "    client.indices.delete(index=index_name)\n",
    "client.indices.create(index=index_name, mappings=mappings)\n",
    "\n",
    "# Define a function to convert DataFrame rows to Elasticsearch documents\n",
    "def generate_docs(data, index_name):\n",
    "    for document in data:\n",
    "        yield dict(_index=index_name, _id=f\"{document['id']}\", _source=document)\n",
    "\n",
    "\n",
    "# Use the Elasticsearch helpers.bulk() method to index the DataFrame data into Elasticsearch\n",
    "load = helpers.bulk(client, generate_docs(songs, index_name), index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for a specific line in a song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use a nested query to look up words in our songs and get the specific passage where this would be mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 3 songs that fit, here are the top results:\n",
      "From Hozier : Take Me to Church : \n",
      "But I love it\n",
      "\n",
      "From Hozier : Work Song : \n",
      "I'm so full of love I could barely eat\n",
      "\n",
      "From Hozier : Someone New : \n",
      "I fall in love just a little ol' little bit\n",
      "I fall in love just a little ol' little bit\n",
      "I fall in love just a little ol' little bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "    \"nested\": {\n",
    "      \"path\": \"lyrics\",\n",
    "      \"query\": {\n",
    "        \"match\": {\n",
    "          \"lyrics.line\": \"love\"\n",
    "        }\n",
    "      },\n",
    "      \"inner_hits\" : {\n",
    "        \"docvalue_fields\" : [\n",
    "          \"lyrics.line.keyword\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "}\n",
    "\n",
    "#Run a simple query, for example looking for problems with the engine\n",
    "response = client.search(index=index_name, query=query)\n",
    "\n",
    "print(f'We get back {response[\"hits\"][\"total\"][\"value\"]} songs that fit, here are the top results:')\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(f'From {hit[\"_source\"][\"artist\"]} : {hit[\"_source\"][\"name\"]}: ')\n",
    "    for inner_hit in hit[\"inner_hits\"][\"lyrics\"][\"hits\"][\"hits\"]:\n",
    "        print(inner_hit[\"_source\"][\"line\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is only returning exact matches, missing out on similar songs about \"lovers\", \"loving\", or any similar phrases which I might still want to find. \n",
    "\n",
    "So we can take this a step further and add a semantic search model into the mix, to help us really look for meaning in the lyrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding ELSER inference for semantic search\n",
    "\n",
    "We will use a [foreach](https://www.elastic.co/guide/en/elasticsearch/reference/current/foreach-processor.html) processor to loop through all lines of the lyrics.\n",
    "\n",
    "See [the ELSER Notebook](https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/search/03-ELSER.ipynb) for a simple get-started quide for semantic search; and [this document chunking example](https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/document-chunking/with-index-pipelines.ipynb) for another instance of embedding inner hits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'task': 'JqYuDbWsRueybLrxY3c9Cg:61831402'})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.ingest.put_pipeline(\n",
    "    id=\"adding_ELSER_to_lyrics\", \n",
    "    processors=\n",
    "    [\n",
    "        {\n",
    "            \"foreach\": {\n",
    "                \"field\": \"lyrics\",\n",
    "                \"processor\": {\n",
    "                    \"inference\": {\n",
    "                        \"model_id\": \".elser_model_2\",\n",
    "                        \"input_output\": [\n",
    "                            {\"input_field\": \"_ingest._value.line\", \"output_field\": \"_ingest._value.tokens\"}\n",
    "                        ],\n",
    "                        \"on_failure\" : [\n",
    "                        {\n",
    "                            \"set\" : {\n",
    "                                \"field\": \"_ingest._value.errors\",\n",
    "                                \"value\": \"failed in foreach processor\"\n",
    "                            }\n",
    "                        }]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "mappings = {\n",
    "    \"dynamic\" : True,\n",
    "    \"properties\" : \n",
    "    {\n",
    "        \"lyrics\": {\n",
    "            \"type\": \"nested\",\n",
    "            \"properties\": {\n",
    "                \"line\" : {\n",
    "                    \"type\": \"text\",\n",
    "                    \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n",
    "                },\n",
    "                \"tokens\": { \n",
    "                    \"type\": \"sparse_vector\" \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#Creating the new index with enriched data\n",
    "index_name_new = \"songs_semantic\"\n",
    "if client.indices.exists(index=index_name_new):\n",
    "    client.indices.delete(index=index_name_new)\n",
    "client.indices.create(index=index_name_new, mappings=mappings)\n",
    "\n",
    "client.reindex(body={\n",
    "      \"source\": {\n",
    "          \"index\": index_name},\n",
    "      \"dest\": {\"index\": index_name_new, \"pipeline\" : \"adding_ELSER_to_lyrics\"}\n",
    "    }, wait_for_completion=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the same query again, but using `text_expansion` on the generated tokens rather than `match` directly on the text field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 8 songs that fit, here are the top results:\n",
      "From Hozier : Someone New : \n",
      "And so I fall in love just a little ol' little bit\n",
      "I fall in love just a little ol' little bit\n",
      "I fall in love just a little ol' little bit\n",
      "\n",
      "From Hozier : Take Me to Church : \n",
      "My lover's got humour\n",
      "But I love it\n",
      "Is when I'm alone with youâ€”\n",
      "\n",
      "From Hozier : Work Song : \n",
      "I'm so full of love I could barely eat\n",
      "She give me toothaches just from kissin' me\n",
      "There's nothing sweeter than my baby\n",
      "\n",
      "From Hozier : Cherry Wine : \n",
      "The way she tells me I'm hers and she is mine\n",
      "Hot and fast and angry as she can be\n",
      "Her eyes and words are so icy\n",
      "\n",
      "From Noah Kahan feat. Hozier : Northern Attitude: \n",
      "You lose your friends, you lose your wife\n",
      "You feelin' right? You feelin' proud?\n",
      "Forgive my northern attitude\n",
      "\n",
      "From Hozier : Butchered Tongue: \n",
      "Singin' at me as the first thing\n",
      "And as a young man, blessed to pass so many road signs\n",
      "A promise softly sung of somewhere else\n",
      "\n",
      "From Hozier feat. Mavis Staples : Nina Cried Power : \n",
      "It's the heaven of the human spirit ringin'\n",
      "It's not the openin' of eyes\n",
      "Power (power)\n",
      "\n",
      "From Hozier : Swan Upon Leda: \n",
      "A crying child pushes a child into the night\n",
      "A husband waits outside\n",
      "Would never belong to angels\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "    \"nested\": {\n",
    "        \"path\": \"lyrics\",\n",
    "        \"query\": {\n",
    "            \"text_expansion\": {\n",
    "                \"lyrics.tokens\": {\n",
    "                    \"model_id\": \".elser_model_2\",\n",
    "                    \"model_text\": \"love\",\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"inner_hits\" : {\n",
    "            \"docvalue_fields\" : [\n",
    "                \"lyrics.line.keyword\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#Run a simple query, for example looking for problems with the engine\n",
    "response = client.search(index=index_name_new, query=query)\n",
    "\n",
    "print(f'We get back {response[\"hits\"][\"total\"][\"value\"]} songs that fit, here are the top results:')\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(f'From {hit[\"_source\"][\"artist\"]} : {hit[\"_source\"][\"name\"]}: ')\n",
    "    for inner_hit in hit[\"inner_hits\"][\"lyrics\"][\"hits\"][\"hits\"]:\n",
    "        print(inner_hit[\"_source\"][\"line\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the semantic model, we not get a lot more results for \"love\". Pretty much every song in the small test dataset actully comes up - which either means our model's threshold is a bit too low for now; or that the lyrics do just happen to all be about love in some way. Both interesting restuls!\n",
    "\n",
    "Now that we've seen this can work, next up we can try with some more data points, additional data sources, and more refined queries or hybrid search techniques. \n",
    "\n",
    "In the next blog - I will add my Spotify listening history and trends to get some more personalized results based on my listening habits and preferences. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
