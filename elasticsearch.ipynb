{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the Elasticsearch client with your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from getpass import getpass\n",
    "\n",
    "#Connect to the elastic cloud server\n",
    "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
    "ELASTIC_API_KEY = getpass(\"Elastic API Key: \")\n",
    "\n",
    "# Create an Elasticsearch client using the provided credentials\n",
    "client = Elasticsearch(\n",
    "    cloud_id=ELASTIC_CLOUD_ID,  # cloud id can be found under deployment management\n",
    "    api_key=ELASTIC_API_KEY, # your username and password for connecting to elastic, found under Deplouments - Security\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the samle lyrics data [we just downloaded with the API.](/lyrics.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/ts_song.json', 'r') as f:\n",
    "  songs = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the data in an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating a nested field for the lyrics so we can search for the inner hits to get the exact lines we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'ts_songs'\n",
    "\n",
    "mappings = {\n",
    "  \"properties\": {\n",
    "    \"lyrics\": {\n",
    "        \"type\": \"nested\",\n",
    "        \"properties\": {\n",
    "          \"line\": {\n",
    "            \"type\": \"text\"\n",
    "          }\n",
    "        }\n",
    "    },\n",
    "  }\n",
    "}\n",
    "\n",
    "# Create the Elasticsearch index with the specified name (delete if already existing)\n",
    "if client.indices.exists(index=index_name):\n",
    "    client.indices.delete(index=index_name)\n",
    "client.indices.create(index=index_name, mappings=mappings)\n",
    "\n",
    "def generate_docs(data, index_name):\n",
    "    for document in data:\n",
    "        yield dict(_index=index_name, _id=f\"{document['id']}\", _source=document)\n",
    "\n",
    "\n",
    "# Use the Elasticsearch helpers.bulk() method to index the DataFrame data into Elasticsearch\n",
    "load = helpers.bulk(client, generate_docs(songs, index_name), index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for a specific line in a song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use a nested query to look up words in our songs and get the specific passage where this would be mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 19 songs that fit, here are the top results:\n",
      "From Taylor Swift : You Are in Love: \n",
      "You are in love, true love\n",
      "\n",
      "From Taylor Swift : Dancing With Our Hands Tied: \n",
      "Oh, keeping you with me, I-\n",
      "\n",
      "From Taylor Swift : Come Back... Be Here: \n",
      "4 AM, the second day\n",
      "\n",
      "From Taylor Swift : New Romantics: \n",
      "Come on, come along with me\n",
      "\n",
      "From Taylor Swift : So It Goes...: \n",
      "Do bad things with you\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def simple_search(query):\n",
    "  query = {\n",
    "      \"nested\": {\n",
    "        \"path\": \"lyrics\",\n",
    "        \"query\": {\n",
    "          \"match\": {\n",
    "            \"lyrics.line\": query\n",
    "          }\n",
    "        },\n",
    "        \"inner_hits\" : {\n",
    "          \"docvalue_fields\" : [\n",
    "            \"lyrics.line.keyword\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "  }\n",
    "\n",
    "  #Run a simple query, for example looking for problems with the engine\n",
    "  response = client.search(index=index_name, query=query)\n",
    "\n",
    "  print(f'We get back {response[\"hits\"][\"total\"][\"value\"]} songs that fit, here are the top results:')\n",
    "  for hit in response[\"hits\"][\"hits\"][0:5]:\n",
    "      print(f'From {hit[\"_source\"][\"artist\"]} : {hit[\"_source\"][\"name\"]}: ')\n",
    "      for inner_hit in hit[\"inner_hits\"][\"lyrics\"][\"hits\"][\"hits\"][0:1]:\n",
    "          print(inner_hit[\"_source\"][\"line\"])\n",
    "      print()\n",
    "\n",
    "simple_search(\"I am in love with you\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is only returning exact matches, missing out on similar songs about \"lovers\", \"loving\", or any similar phrases which I might still want to find. \n",
    "\n",
    "So we can take this a step further and add a semantic search model into the mix, to help us really look for meaning in the lyrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding ELSER inference for semantic search\n",
    "\n",
    "We will use a [foreach](https://www.elastic.co/guide/en/elasticsearch/reference/current/foreach-processor.html) processor to loop through all lines of the lyrics.\n",
    "\n",
    "See [the ELSER Notebook](https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/search/03-ELSER.ipynb) for a simple get-started quide for semantic search; and [this document chunking example](https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/document-chunking/with-index-pipelines.ipynb) for another instance of embedding inner hits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'task': 'eclQBhHoS0CN09g-_bZM5w:63679788'})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.ingest.put_pipeline(\n",
    "    id=\"adding_ELSER_to_lyrics\", \n",
    "    processors=\n",
    "    [\n",
    "        {\n",
    "            \"foreach\": {\n",
    "                \"field\": \"lyrics\",\n",
    "                \"processor\": {\n",
    "                    \"inference\": {\n",
    "                        \"model_id\": \".elser_model_2\",\n",
    "                        \"input_output\": [\n",
    "                            {\"input_field\": \"_ingest._value.line\", \"output_field\": \"_ingest._value.tokens\"}\n",
    "                        ],\n",
    "                        \"on_failure\" : [\n",
    "                        {\n",
    "                            \"set\" : {\n",
    "                                \"field\": \"_ingest._value.errors\",\n",
    "                                \"value\": \"failed in foreach processor\"\n",
    "                            }\n",
    "                        }]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "mappings = {\n",
    "    \"dynamic\" : True,\n",
    "    \"properties\" : \n",
    "    {\n",
    "        \"lyrics\": {\n",
    "            \"type\": \"nested\",\n",
    "            \"properties\": {\n",
    "                \"line\" : {\n",
    "                    \"type\": \"text\",\n",
    "                    \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n",
    "                },\n",
    "                \"tokens\": { \n",
    "                    \"type\": \"sparse_vector\" \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#Creating the new index with enriched data\n",
    "index_name_new = \"ts_songs_semantic\"\n",
    "if client.indices.exists(index=index_name_new):\n",
    "    client.indices.delete(index=index_name_new)\n",
    "client.indices.create(index=index_name_new, mappings=mappings)\n",
    "\n",
    "client.reindex(body={\n",
    "      \"source\": {\n",
    "          \"index\": index_name},\n",
    "      \"dest\": {\"index\": index_name_new, \"pipeline\" : \"adding_ELSER_to_lyrics\"}\n",
    "    }, wait_for_completion=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the same query again, but using `text_expansion` on the generated tokens rather than `match` directly on the text field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 19 songs that fit, here are the top results:\n",
      "From Taylor Swift : You Are in Love: \n",
      "You are in love\n",
      "\n",
      "From Taylor Swift : Gorgeous: \n",
      "(I hate you so much)\n",
      "\n",
      "From Taylor Swift : End Game (Ft. Ed Sheeran & Future): \n",
      "You love it, I love it, too 'cause you my type (you my type)\n",
      "\n",
      "From Taylor Swift : Come Back... Be Here: \n",
      "This is falling in love in the cruelest way\n",
      "\n",
      "From Taylor Swift : Don't Blame Me: \n",
      "You're lovin' me\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def semantic_search(query):\n",
    "    query = {\n",
    "        \"nested\": {\n",
    "            \"path\": \"lyrics\",\n",
    "            \"query\": {\n",
    "                \"text_expansion\": {\n",
    "                    \"lyrics.tokens\": {\n",
    "                        \"model_id\": \".elser_model_2\",\n",
    "                        \"model_text\": query,\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"inner_hits\" : {\n",
    "                \"docvalue_fields\" : [\n",
    "                    \"lyrics.line.keyword\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    #Run a simple query, for example looking for problems with the engine\n",
    "    response = client.search(index=index_name_new, query=query)\n",
    "\n",
    "    print(f'We get back {response[\"hits\"][\"total\"][\"value\"]} songs that fit, here are the top results:')\n",
    "    for hit in response[\"hits\"][\"hits\"][0:5]:\n",
    "        print(f'From {hit[\"_source\"][\"artist\"]} : {hit[\"_source\"][\"name\"]}: ')\n",
    "        for inner_hit in hit[\"inner_hits\"][\"lyrics\"][\"hits\"][\"hits\"][0:1]:\n",
    "            print(inner_hit[\"_source\"][\"line\"])\n",
    "        print()\n",
    "\n",
    "semantic_search(\"I am in love with you\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the new semantic search layer, we actually get back pretty much every song in our sample dataset. \n",
    "\n",
    "This could either mean the model has too low of a treshold for the match, or that simply all songs are in some form about love. \n",
    "\n",
    "Let's try some more specific searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 19 songs that fit, here are the top results:\n",
      "From Taylor Swift : King of My Heart: \n",
      "And all at once, you are the one I have been waiting for\n",
      "\n",
      "From Taylor Swift : This Is Why We Can't Have Nice Things: \n",
      "This is why we can't have-\n",
      "\n",
      "From Taylor Swift : Girl at Home: \n",
      "This I have previously learned\n",
      "\n",
      "From Taylor Swift : Gorgeous: \n",
      "There's nothing I hate more than what I can't have\n",
      "\n",
      "From Taylor Swift : The Moment I Knew: \n",
      "And I would've been so happy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simple_search(\"I have been betrayed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 19 songs that fit, here are the top results:\n",
      "From Taylor Swift : This Is Why We Can't Have Nice Things: \n",
      "Friends don't try to trick you\n",
      "\n",
      "From Taylor Swift : I Did Something Bad: \n",
      "And I let them think they saved me\n",
      "\n",
      "From Taylor Swift : Gorgeous: \n",
      "(I hate you so much)\n",
      "\n",
      "From Taylor Swift : Dancing With Our Hands Tied: \n",
      "I, I loved you in spite of\n",
      "\n",
      "From Taylor Swift : Getaway Car: \n",
      "'Cause us traitors never win\n",
      "\n"
     ]
    }
   ],
   "source": [
    "semantic_search(\"I have been betrayed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 19 songs that fit, here are the top results:\n",
      "From Taylor Swift : I Did Something Bad: \n",
      "Light me up (light me up), light me up (light me up)\n",
      "\n",
      "From Taylor Swift : New Romantics: \n",
      "Come on, come along with me\n",
      "\n",
      "From Taylor Swift : Look What You Made Me Do: \n",
      "The role you made me play\n",
      "\n",
      "From Taylor Swift : Dancing With Our Hands Tied: \n",
      "Oh, keeping you with me, I-\n",
      "\n",
      "From Taylor Swift : Girl at Home: \n",
      "Want to see you pick up your phone\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simple_search(\"you broke up with me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 19 songs that fit, here are the top results:\n",
      "From Taylor Swift : Gorgeous: \n",
      "You've ruined my life by not being mine\n",
      "\n",
      "From Taylor Swift : This Is Why We Can't Have Nice Things: \n",
      "Because you break them\n",
      "\n",
      "From Taylor Swift : You Are in Love: \n",
      "You are in love\n",
      "\n",
      "From Taylor Swift : Look What You Made Me Do: \n",
      "Isn't cool, no, I don't like you (oh)\n",
      "\n",
      "From Taylor Swift : Girl at Home: \n",
      "You're about to lose your girl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "semantic_search(\"you broke up with me\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic search does seem to capture the meaning better, however it still seems like the spirit of the songs isn't fully represented. This may be due to the chunking strategy. In these examples, each line of the lyrics is its own document, however the sentences or paragraphs end up broken up and some of the context is lost. \n",
    "\n",
    "This brings up a very important point about semantic search - performance isn't only determined by the model chosen, but also the way data is processed and introduced to the model.\n",
    "Let's try a few strategies to offer the model more context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding chunking for context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add multiple versions of our documents (or songs in this instance) to the index. For this simple example, we've chosen three dymensions: the entire lyrics as one entry, the line-by-line approach we just tested above, and a custom recursive chunking strategy that is an industry best practice when working with LLMs.\n",
    "\n",
    "The chunker gives us paragraphs of about 150 characters, with some overlap. The overlap means some lines get included in multiple chunks with a rolling window appraoch to preserve as much context as possible in each chunk.\n",
    "\n",
    "(insert more stats from data processing notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'ts_songs_chunks'\n",
    "\n",
    "mappings = {\n",
    "  \"properties\": {\n",
    "    \"lyrics\": {\n",
    "      \"type\": \"nested\",\n",
    "      \"properties\": {\n",
    "        \"line\": {\n",
    "          \"type\": \"text\"\n",
    "        }\n",
    "      },\n",
    "    },\n",
    "    \"full_lyrics\": {\n",
    "      \"type\": \"nested\",\n",
    "      \"properties\": {\n",
    "        \"line\": {\n",
    "          \"type\": \"text\"\n",
    "        }\n",
    "      }, \n",
    "    },\n",
    "    \"chunks\": {\n",
    "      \"type\": \"nested\",\n",
    "      \"properties\": {\n",
    "        \"line\": {\n",
    "          \"type\": \"text\"\n",
    "        }\n",
    "      },   \n",
    "    },\n",
    "  }\n",
    "}\n",
    "\n",
    "# Create the Elasticsearch index with the specified name (delete if already existing)\n",
    "if client.indices.exists(index=index_name):\n",
    "    client.indices.delete(index=index_name)\n",
    "client.indices.create(index=index_name, mappings=mappings)\n",
    "\n",
    "def generate_docs(data, index_name):\n",
    "    for document in data:\n",
    "        yield dict(_index=index_name, _id=f\"{document['id']}\", _source=document)\n",
    "\n",
    "\n",
    "# Use the Elasticsearch helpers.bulk() method to index the DataFrame data into Elasticsearch\n",
    "load = helpers.bulk(client, generate_docs(songs, index_name), index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding the search function now that we have more parameter options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 19 songs that fit, here are the top results:\n",
      "From Taylor Swift : You Are in Love: \n",
      "From Taylor Swift : Dancing With Our Hands Tied: \n",
      "From Taylor Swift : Come Back... Be Here: \n",
      "From Taylor Swift : ...Ready for It?: \n",
      "From Taylor Swift : Getaway Car: \n"
     ]
    }
   ],
   "source": [
    "def simple_search(query, path, content=True):\n",
    "  # path determines on which field to search (full_lyrics, lyrics, or chunks in this case)\n",
    "  # content determines if we print the lyrics matched or only the song title\n",
    "  query = {\n",
    "        \"nested\": {\n",
    "          \"path\": path,\n",
    "          \"query\": {\n",
    "            \"match\": {\n",
    "              path + \".line\": query\n",
    "            }\n",
    "          },\n",
    "          \"inner_hits\" : {\n",
    "            \"docvalue_fields\" : [\n",
    "              path + \".line.keyword\"\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "    }\n",
    "\n",
    "  #Run a simple query, for example looking for problems with the engine\n",
    "  response = client.search(index=index_name, query=query)\n",
    "\n",
    "  print(f'We get back {response[\"hits\"][\"total\"][\"value\"]} songs that fit, here are the top results:')\n",
    "  for hit in response[\"hits\"][\"hits\"][0:5]:\n",
    "      print(f'From {hit[\"_source\"][\"artist\"]} : {hit[\"_source\"][\"name\"]}: ')\n",
    "      if content:\n",
    "        for inner_hit in hit[\"inner_hits\"][path][\"hits\"][\"hits\"][0:1]:\n",
    "            print(inner_hit[\"_source\"][\"line\"])\n",
    "\n",
    "\n",
    "query = \"I am in love with you\"\n",
    "path = \"chunks\"\n",
    "simple_search(query, path, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 19 songs that fit, here are the top results:\n",
      "From Taylor Swift : You Are in Love: \n",
      "From Taylor Swift : Dancing With Our Hands Tied: \n",
      "From Taylor Swift : Come Back... Be Here: \n",
      "From Taylor Swift : New Romantics: \n",
      "From Taylor Swift : So It Goes...: \n"
     ]
    }
   ],
   "source": [
    "query = \"I am in love with you\"\n",
    "simple_search(query, \"lyrics\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 19 songs that fit, here are the top results:\n",
      "From Taylor Swift : Come Back... Be Here: \n",
      "From Taylor Swift : Girl at Home: \n",
      "From Taylor Swift : You Are in Love: \n",
      "From Taylor Swift : Dancing With Our Hands Tied: \n",
      "From Taylor Swift : End Game (Ft. Ed Sheeran & Future): \n"
     ]
    }
   ],
   "source": [
    "query = \"I am in love with you\"\n",
    "simple_search(query, \"full_lyrics\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that different chunking sizes give different results for the same query. Some songs appear in all results but ranked differently, while others are unique to a certain chunk-sized search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now also generate embeddings for the various sizes and see how those also perform differently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'task': 'JqYuDbWsRueybLrxY3c9Cg:95601039'})"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = {\n",
    "    \"inference\": {\n",
    "        \"model_id\": \".elser_model_2\",\n",
    "        \"input_output\": [\n",
    "            {\"input_field\": \"_ingest._value.line\", \"output_field\": \"_ingest._value.tokens\"}\n",
    "        ],\n",
    "        \"on_failure\" : [{\n",
    "            \"set\" : {\n",
    "                \"field\": \"_ingest._value.errors\",\n",
    "                \"value\": \"failed in foreach processor\"\n",
    "            }\n",
    "        }]\n",
    "    }\n",
    "}\n",
    "\n",
    "client.ingest.put_pipeline(\n",
    "    id=\"adding_ELSER_to_lyrics_chunks\", \n",
    "    processors=\n",
    "    [\n",
    "        {\n",
    "            \"foreach\": {\n",
    "                \"field\": \"lyrics\",\n",
    "                \"processor\": processor\n",
    "            },\n",
    "            \"foreach\": {\n",
    "                \"field\": \"full_lyrics\",\n",
    "                \"processor\": processor\n",
    "            },\n",
    "            \"foreach\": {\n",
    "                \"field\": \"chunks\",\n",
    "                \"processor\": processor\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "properties = {\n",
    "    \"line\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n",
    "    },\n",
    "    \"tokens\": { \n",
    "        \"type\": \"sparse_vector\" \n",
    "    }\n",
    "}\n",
    "\n",
    "mappings = {\n",
    "    \"dynamic\" : True,\n",
    "    \"properties\" : \n",
    "    {\n",
    "        \"lyrics\": {\n",
    "            \"type\": \"nested\",\n",
    "            \"properties\": properties\n",
    "        },\n",
    "        \"full_lyrics\": {\n",
    "            \"type\": \"nested\",\n",
    "            \"properties\": properties\n",
    "        },\n",
    "        \"chunks\": {\n",
    "            \"type\": \"nested\",\n",
    "            \"properties\": properties\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "#Creating the new index with enriched data\n",
    "index_name_new = \"ts_songs_semantic_chunked\"\n",
    "if client.indices.exists(index=index_name_new):\n",
    "    client.indices.delete(index=index_name_new)\n",
    "client.indices.create(index=index_name_new, mappings=mappings)\n",
    "\n",
    "client.reindex(body={\n",
    "      \"source\": {\n",
    "          \"index\": index_name},\n",
    "      \"dest\": {\"index\": index_name_new, \"pipeline\" : \"adding_ELSER_to_lyrics_chunks\"}\n",
    "    }, wait_for_completion=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, path, content=True):\n",
    "    query = {\n",
    "        \"nested\": {\n",
    "            \"path\": path,\n",
    "            \"query\": {\n",
    "                \"text_expansion\": {\n",
    "                    path + \".tokens\": {\n",
    "                        \"model_id\": \".elser_model_2\",\n",
    "                        \"model_text\": query,\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"inner_hits\" : {\n",
    "                \"docvalue_fields\" : [\n",
    "                    path + \".line.keyword\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    #Run a simple query, for example looking for problems with the engine\n",
    "    response = client.search(index=index_name_new, query=query)\n",
    "\n",
    "    print(f'We get back {response[\"hits\"][\"total\"][\"value\"]} songs that fit, here are the top results:')\n",
    "    for hit in response[\"hits\"][\"hits\"][0:5]:\n",
    "        print(f'From {hit[\"_source\"][\"artist\"]} : {hit[\"_source\"][\"name\"]}: ')\n",
    "        if content:\n",
    "            for inner_hit in hit[\"inner_hits\"][path][\"hits\"][\"hits\"][0:1]:\n",
    "                print(inner_hit[\"_source\"][\"line\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 0 songs that fit, here are the top results:\n"
     ]
    }
   ],
   "source": [
    "query = \"I am in love with you\"\n",
    "semantic_search(query, \"lyrics\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get back 19 songs that fit, here are the top results:\n",
      "From Taylor Swift : You Are in Love: \n",
      "From Taylor Swift : Gorgeous: \n",
      "From Taylor Swift : Don't Blame Me: \n",
      "From Taylor Swift : Dancing With Our Hands Tied: \n",
      "From Taylor Swift : Delicate: \n"
     ]
    }
   ],
   "source": [
    "query = \"I am in love with you\"\n",
    "semantic_search(query, \"chunks\", False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
